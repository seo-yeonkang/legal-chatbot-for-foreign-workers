# =============================================================================
# setup.py - ë°°í¬ ì‹œì  ì‚¬ì „ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸
# =============================================================================

import os
import sys
import gdown
import zipfile
import pickle
import json
from pathlib import Path
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import torch

# ì„¤ì • ì„í¬íŠ¸
import config

def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    print("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘...")
    config.DATA_DIR.mkdir(exist_ok=True)
    config.MODELS_DIR.mkdir(exist_ok=True)
    print("âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ")

def download_chinese_model():
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ì¤‘êµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ“¥ ì¤‘êµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    
    # ì´ë¯¸ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
    if config.CHINESE_MODEL_LOCAL_PATH.exists():
        print("âœ… ì¤‘êµ­ì–´ ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return True
    
    try:
        # êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ í´ë” ë‹¤ìš´ë¡œë“œ
        folder_url = f"https://drive.google.com/drive/folders/{config.CHINESE_MODEL_GDRIVE_ID}"
        gdown.download_folder(folder_url, output=str(config.MODELS_DIR), quiet=False)
        
        # í´ë”ëª… ì •ë¦¬
        downloaded_folder = config.CHINESE_MODEL_LOCAL_PATH
        if not downloaded_folder.exists():
            for folder in config.MODELS_DIR.iterdir():
                if folder.is_dir() and folder.name != "chinese_model" and not folder.name.startswith("."):
                    folder.rename(downloaded_folder)
                    break
        
        # ë‹¤ìš´ë¡œë“œ ë§ˆì»¤ ìƒì„±
        download_marker = config.MODELS_DIR / ".chinese_model_downloaded"
        download_marker.touch()
        
        print("âœ… ì¤‘êµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ ì¤‘êµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def download_vietnamese_model():
    """ë² íŠ¸ë‚¨ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ“¥ ë² íŠ¸ë‚¨ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    
    try:
        # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ (ìºì‹œì— ì €ì¥ë¨)
        model = AutoModelForSeq2SeqLM.from_pretrained(config.VIETNAMESE_MODEL)
        tokenizer = AutoTokenizer.from_pretrained(config.VIETNAMESE_TOKENIZER)
        
        print("âœ… ë² íŠ¸ë‚¨ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ ë² íŠ¸ë‚¨ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def build_embeddings_and_indexes():
    """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
    print("ğŸ“š ì„ë² ë”© ì‹œìŠ¤í…œ êµ¬ì¶• ì¤‘...")
    
    try:
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ì¤‘êµ­ì–´ ì¸ë±ìŠ¤ êµ¬ì¶•
        print("ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ ë²•ë¥  ë°ì´í„° ì¸ë±ì‹± ì¤‘...")
        cn_success = build_language_index(
            embedding_model, 'zh', 
            config.CN_LAW_DATA_PATH,
            config.CN_FAISS_INDEX_PATH,
            config.CN_PASSAGES_PATH
        )
        
        # ë² íŠ¸ë‚¨ì–´ ì¸ë±ìŠ¤ êµ¬ì¶•  
        print("ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ì–´ ë²•ë¥  ë°ì´í„° ì¸ë±ì‹± ì¤‘...")
        vn_success = build_language_index(
            embedding_model, 'vi',
            config.VN_LAW_DATA_PATH, 
            config.VN_FAISS_INDEX_PATH,
            config.VN_PASSAGES_PATH
        )
        
        if cn_success and vn_success:
            print("âœ… ëª¨ë“  ì–¸ì–´ ì¸ë±ì‹± ì™„ë£Œ")
            return True
        else:
            print("âš ï¸ ì¼ë¶€ ì–¸ì–´ ì¸ë±ì‹± ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì‹œìŠ¤í…œ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        return False

def build_language_index(embedding_model, language, jsonl_path, faiss_path, passages_path):
    """íŠ¹ì • ì–¸ì–´ì˜ FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
    try:
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê±´ë„ˆë›°ê¸°
        if faiss_path.exists() and passages_path.exists():
            print(f"âœ… {language} ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            return True
        
        # JSONL ë°ì´í„° ë¡œë“œ
        passages, metadata = load_jsonl_data(jsonl_path)
        if not passages:
            print(f"âŒ {language} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_path}")
            return False
        
        print(f"ğŸ“„ {language} ë¬¸ì„œ {len(passages)}ê°œ ì„ë² ë”© ìƒì„± ì¤‘...")
        
        # ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
        embeddings = embedding_model.encode(
            passages,
            show_progress_bar=True,
            batch_size=32,
            normalize_embeddings=True
        )
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        dimension = embeddings.shape[1]
        faiss_index = faiss.IndexFlatL2(dimension)
        faiss_index.add(embeddings.astype('float32'))
        
        # ì €ì¥
        faiss.write_index(faiss_index, str(faiss_path))
        
        with open(passages_path, 'wb') as f:
            pickle.dump({
                'passages': passages,
                'metadata': metadata
            }, f)
        
        print(f"âœ… {language} ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {len(passages)}ê°œ ë¬¸ì„œ")
        return True
        
    except Exception as e:
        print(f"âŒ {language} ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
        return False

def load_jsonl_data(jsonl_path):
    """JSONL íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    passages = []
    metadata = []
    
    try:
        with open(jsonl_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    data = json.loads(line.strip())
                    if "Trans_Sentence" in data:
                        passages.append(data["Trans_Sentence"])
                        metadata.append(data)
                except json.JSONDecodeError:
                    print(f"âš ï¸ Line {line_num}: JSON íŒŒì‹± ì˜¤ë¥˜")
                    continue
        
        return passages, metadata
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jsonl_path}")
        return [], []

def verify_setup():
    """ì„¤ì • ì™„ë£Œ ê²€ì¦"""
    print("ğŸ” ì„¤ì • ê²€ì¦ ì¤‘...")
    
    checks = []
    
    # ì¤‘êµ­ì–´ ëª¨ë¸ í™•ì¸
    chinese_model_ok = config.CHINESE_MODEL_LOCAL_PATH.exists()
    checks.append(("ì¤‘êµ­ì–´ ëª¨ë¸", chinese_model_ok))
    
    # ì¤‘êµ­ì–´ ì¸ë±ìŠ¤ í™•ì¸
    cn_index_ok = config.CN_FAISS_INDEX_PATH.exists() and config.CN_PASSAGES_PATH.exists()
    checks.append(("ì¤‘êµ­ì–´ ì¸ë±ìŠ¤", cn_index_ok))
    
    # ë² íŠ¸ë‚¨ì–´ ì¸ë±ìŠ¤ í™•ì¸
    vn_index_ok = config.VN_FAISS_INDEX_PATH.exists() and config.VN_PASSAGES_PATH.exists()
    checks.append(("ë² íŠ¸ë‚¨ì–´ ì¸ë±ìŠ¤", vn_index_ok))
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“‹ ì„¤ì • ê²€ì¦ ê²°ê³¼:")
    all_ok = True
    for name, status in checks:
        status_str = "âœ…" if status else "âŒ"
        print(f"  {status_str} {name}: {'OK' if status else 'FAIL'}")
        if not status:
            all_ok = False
    
    return all_ok

def create_deployment_marker():
    """ë°°í¬ ì™„ë£Œ ë§ˆì»¤ ìƒì„±"""
    marker_file = config.DATA_DIR / ".deployment_ready"
    marker_data = {
        "timestamp": str(Path(__file__).stat().st_mtime),
        "version": "1.0",
        "chinese_model": str(config.CHINESE_MODEL_LOCAL_PATH),
        "models_ready": True
    }
    
    with open(marker_file, 'w') as f:
        json.dump(marker_data, f, indent=2)
    
    print("âœ… ë°°í¬ ì¤€ë¹„ ì™„ë£Œ ë§ˆì»¤ ìƒì„±ë¨")

def main():
    """ë©”ì¸ ì„¤ì • í•¨ìˆ˜"""
    print("ğŸš€ ë°°í¬ ì‹œì  ì‚¬ì „ êµ¬ì¶• ì‹œì‘!")
    print("=" * 50)
    
    # 1. ë””ë ‰í† ë¦¬ ìƒì„±
    setup_directories()
    
    # 2. ì¤‘êµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if not download_chinese_model():
        print("âŒ ì¤‘êµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ìˆ˜ë™ ì„¤ì • í•„ìš”")
        return False
    
    # 3. ë² íŠ¸ë‚¨ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if not download_vietnamese_model():
        print("âŒ ë² íŠ¸ë‚¨ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return False
    
    # 4. ì„ë² ë”© ì‹œìŠ¤í…œ êµ¬ì¶•
    if not build_embeddings_and_indexes():
        print("âŒ ì„ë² ë”© ì‹œìŠ¤í…œ êµ¬ì¶• ì‹¤íŒ¨")
        return False
    
    # 5. ê²€ì¦
    if verify_setup():
        create_deployment_marker()
        print("\nğŸ‰ ë°°í¬ ì‚¬ì „ êµ¬ì¶• ì™„ë£Œ!")
        print("ì´ì œ ì•± ì‹¤í–‰ ì‹œ ì¦‰ì‹œ ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë©ë‹ˆë‹¤.")
        return True
    else:
        print("\nâŒ ì¼ë¶€ êµ¬ì„± ìš”ì†Œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
