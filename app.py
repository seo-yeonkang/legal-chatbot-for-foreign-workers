# =============================================================================
# app.py - ë©”ì¸ Streamlit ì•±
# =============================================================================

import streamlit as st
import os
from langdetect import detect, DetectorFactory
from pathlib import Path
import sys
import traceback
import torch

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# ì–¸ì–´ ê°ì§€ ì‹œë“œ ê³ ì • (ì¼ê´€ì„±ì„ ìœ„í•´)
DetectorFactory.seed = 0

# ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
import config
from utils import (
    load_tokenizer,
    load_embeddings_and_index,
    build_prompt,
    generate_answer,
    common
)
from utils.common import mark_deployment_ready
from utils.embedding_index import search_similar_passages, is_deployment_ready
from utils.generator import load_generation_models
import pickle
import faiss

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=config.PAGE_TITLE,
    page_icon=config.PAGE_ICON,
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
        border-bottom: 2px solid #e0e0e0;
        margin-bottom: 2rem;
    }
    .chat-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .legal-docs {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    .answer-box {
        background-color: #e8f5e8;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ í—¤ë”
st.markdown(f"""
<div class="main-header">
    <h1>{config.PAGE_ICON} {config.PAGE_TITLE}</h1>
    <p>ì¤‘êµ­ì–´ì™€ ë² íŠ¸ë‚¨ì–´ë¥¼ ì§€ì›í•˜ëŠ” AI ë²•ë¥  ìƒë‹´ ì„œë¹„ìŠ¤</p>
</div>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("### ğŸ“‹ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. ì¤‘êµ­ì–´ ğŸ‡¨ğŸ‡³ ë˜ëŠ” ë² íŠ¸ë‚¨ì–´ ğŸ‡»ğŸ‡³ë¡œ ì§ˆë¬¸ ì…ë ¥
    2. ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ ìë™ ê²€ìƒ‰
    3. AIê°€ ë²•ë¥  ì¡°ë¬¸ì— ê¸°ë°˜í•œ ë‹µë³€ ì œê³µ
    """)
    
    st.markdown("### âš ï¸ ì£¼ì˜ì‚¬í•­")
    st.markdown("""
    - ë³¸ ì„œë¹„ìŠ¤ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤
    - ì¤‘ìš”í•œ ë²•ë¥  ë¬¸ì œëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”
    - ë‹µë³€ì˜ ì •í™•ì„±ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    """)
    
    st.markdown("### ğŸŒ ì§€ì› ì–¸ì–´")
    st.markdown("- ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ (Chinese)")
    st.markdown("- ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ì–´ (Vietnamese)")
    

@st.cache_resource(show_spinner=False)
def get_shared_resources():
    """í•œ ë²ˆë§Œ ë¡œë“œí•´ì„œ ëª¨ë“  ì„¸ì…˜ì´ ê³µìœ """
    embed_model, cn_idx, cn_pass, cn_meta, vn_idx, vn_pass, vn_meta = load_embeddings_and_index()
    chinese_model, vietnamese_model = load_generation_models()
    return {
        "embed_model": embed_model,
        "cn_index": cn_idx,  "cn_passages": cn_pass,  "cn_meta": cn_meta,
        "vn_index": vn_idx,  "vn_passages": vn_pass,  "vn_meta": vn_meta,
        "ch_model":  chinese_model,
        "vn_model":  vietnamese_model,
    }

def init_session():
    if "initialized" in st.session_state:
        return
    data = get_shared_resources()

    st.session_state.embed_model       = data["embed_model"]
    st.session_state.cn_index          = data["cn_index"]
    st.session_state.cn_passages       = data["cn_passages"]
    st.session_state.cn_metadata       = data["cn_meta"]
    st.session_state.vn_index          = data["vn_index"]
    st.session_state.vn_passages       = data["vn_passages"]
    st.session_state.vn_metadata       = data["vn_meta"]
    st.session_state.chinese_model     = data["ch_model"]
    st.session_state.vietnamese_model  = data["vn_model"]

    st.session_state.initialized = True

# ë©”ì¸ ì½˜í…ì¸ 
def main():
    init_session()
    st.success("ğŸš€ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
    
    # ì§ˆë¬¸ ì…ë ¥
    st.markdown("### ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    def set_example(text):
        st.session_state.question_input = text      # <- ì½œë°± ë‚´ë¶€ì—ì„œ ì•ˆì „

    st.markdown("#### ğŸ“ ì˜ˆì‹œ ì§ˆë¬¸")
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¤ºä¾‹**")
        st.button(
            "å¤–å›½äººå·¥ä½œåœ°ç‚¹å˜æ›´æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ",
            key="zh_example",
            on_click=set_example,
            args=("å¤–å›½äººå·¥ä½œåœ°ç‚¹å˜æ›´æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ",)
        )
    
    with col2:
        st.markdown("**ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t**")
        st.button(
            "Äiá»u kiá»‡n thay Ä‘á»•i nÆ¡i lÃ m viá»‡c cá»§a ngÆ°á»i nÆ°á»›c ngoÃ i lÃ  gÃ¬?",
            key="vi_example",
            on_click=set_example,
            args=("Äiá»u kiá»‡n thay Ä‘á»•i nÆ¡i lÃ m viá»‡c cá»§a ngÆ°á»i nÆ°á»›c ngoÃ i lÃ  gÃ¬?",)
        )
    
    # â–¶ï¸ ì´ì œ í…ìŠ¤íŠ¸ ì…ë ¥ ìœ„ì ¯ì„ **ë²„íŠ¼ ì•„ë˜** ë˜ëŠ” ìœ„ì ¯ ìƒì„± ë’¤ ê°’ ì½ê¸°ë§Œ
    question = st.text_input(
        "ì§ˆë¬¸",
        key="question_input",
        label_visibility="collapsed",
        placeholder="ì¤‘êµ­ì–´ ë˜ëŠ” ë² íŠ¸ë‚¨ì–´ë¡œ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."
    )
        
    # ì§ˆë¬¸ ì²˜ë¦¬
    if st.button("ì§ˆë¬¸í•˜ê¸°") and question.strip():
        process_question(question.strip())

from langdetect import detect, DetectorFactory
import regex as re
DetectorFactory.seed = 0      # ì´ë¯¸ ìˆìŒ


def safe_detect(text: str) -> str:
    """ì§§ì€Â·í˜¼í•© ë¬¸ì¥ì— ëŒ€í•œ ë³´ì • í¬í•¨ ì¤‘êµ­ì–´/ë² íŠ¸ë‚¨ì–´ ê°ì§€"""
    try:
        lang = detect(text)
    except:
        lang = "unknown"

    # --- ë³´ì • â‘  : ì¤‘êµ­ì–´ ê¸€ì ì¡´ì¬í•˜ë©´ ê°•ì œ zh ---
    if re.search(r"\p{Han}", text):
        return "zh"

    # --- ë³´ì • â‘¡ : ë² íŠ¸ë‚¨ì–´ íŠ¹ìˆ˜ ë¬¸ì ì¡´ì¬í•˜ë©´ ê°•ì œ vi ---
    if re.search(r"[ÄƒÃ¢Ä‘ÃªÃ´Æ¡Æ°Ä‚Ã‚ÄÃŠÃ”Æ Æ¯]", text):
        return "vi"

    return lang


def process_question(question: str):
    """ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ìƒì„±"""
    if "initialized" not in st.session_state:
        st.warning("ğŸ”„ ì‹œìŠ¤í…œì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return
        
    if ('chinese_model' not in st.session_state or
        'vietnamese_model' not in st.session_state):
        chinese_model, vietnamese_model = load_generation_models()
        st.session_state.chinese_model     = chinese_model
        st.session_state.vietnamese_model  = vietnamese_model
    
    try:
        # ì–¸ì–´ ê°ì§€
        detected_lang = safe_detect(question)
        
        # ì§€ì›ë˜ëŠ” ì–¸ì–´ í™•ì¸
        if detected_lang not in ['zh', 'vi']:
            st.warning("âš ï¸ ì¤‘êµ­ì–´ ë˜ëŠ” ë² íŠ¸ë‚¨ì–´ë¡œë§Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
            return
        
        # ì–¸ì–´ í‘œì‹œ
        lang_display = {"zh": "ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´", "vi": "ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ì–´"}
        st.info(f"ê°ì§€ëœ ì–¸ì–´: {lang_display.get(detected_lang, detected_lang)}")
        
        # ì–¸ì–´ì— ë”°ë¥¸ ì¸ë±ìŠ¤ ë° íŒ¨ì‹œì§€ ì„ íƒ (ìºì‹œì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
        if detected_lang == "zh":
            faiss_index = st.session_state.cn_index
            passages = st.session_state.cn_passages
            metadata = st.session_state.cn_metadata
        else:  # detected_lang == "vi"
            faiss_index = st.session_state.vn_index  
            passages = st.session_state.vn_passages
            metadata = st.session_state.vn_metadata
        
        # í•´ë‹¹ ì–¸ì–´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if faiss_index is None or passages is None:
            lang_name = "ì¤‘êµ­ì–´" if detected_lang == "zh" else "ë² íŠ¸ë‚¨ì–´"
            st.error(f"âŒ {lang_name} ë²•ë¥  ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ (ë” ë¹ ë¥¸ ê²€ìƒ‰)
        with st.spinner("ğŸ” ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ ì¤‘..."):
            retrieved_docs = search_similar_passages(
                st.session_state.embed_model,
                faiss_index,
                passages,
                question,
                k=config.MAX_RETRIEVED_DOCS
            )
        
        if not retrieved_docs:
            st.warning("ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²€ìƒ‰ëœ ë²•ë¥  ì¡°ë¬¸ í‘œì‹œ
        with st.expander("ğŸ” ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸", expanded=True):
            st.markdown('<div class="legal-docs">', unsafe_allow_html=True)
            for i, doc in enumerate(retrieved_docs, 1):
                score = doc.get('score', 0)
                st.markdown(f"**{i}. ë²•ì¡°ë¬¸** (ìœ ì‚¬ë„: {score:.3f})")
                st.markdown(f"{doc['text']}")
                st.markdown("---")
            st.markdown('</div>', unsafe_allow_html=True)
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        tokenizer = load_tokenizer(detected_lang)
        if tokenizer is None:
            st.error("í† í¬ë‚˜ì´ì € ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = build_prompt(question, retrieved_docs, detected_lang)
        
        # ëª¨ë¸ ì„ íƒ (ìºì‹œì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
        model = (st.session_state.chinese_model if detected_lang == "zh" 
                else st.session_state.vietnamese_model)
        
        # ë‹µë³€ ìƒì„± (ë” ë¹ ë¥¸ ìƒì„±)
        with st.spinner("ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘..."):
            answer = generate_answer(prompt, model, tokenizer)
        
        # ë‹µë³€ í‘œì‹œ
        st.markdown("### ğŸ’¡ AI ë²•ë¥  ìƒë‹´ ë‹µë³€")
        st.markdown('<div class="answer-box">', unsafe_allow_html=True)
        st.markdown(answer)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ì¶”ê°€ ì•ˆë‚´
        st.markdown("---")
        st.markdown("**âš ï¸ ë©´ì±…ì¡°í•­:** ë³¸ ë‹µë³€ì€ AIê°€ ìƒì„±í•œ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìƒë‹´ì€ ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        # ì„±ëŠ¥ ì •ë³´ (ê°„ë‹¨í•˜ê²Œ)
        if 'app_fully_initialized' in st.session_state:
            with st.expander("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ì •ë³´"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸš€ ëª¨ë“œ", "ê³ ì† ìºì‹œ")
                with col2:
                    device = "GPU" if torch.cuda.is_available() else "CPU"
                    st.metric("ğŸ’» ì²˜ë¦¬ ì¥ì¹˜", device)
                with col3:
                    docs_count = len(retrieved_docs) if retrieved_docs else 0
                    st.metric("ğŸ“„ ê²€ìƒ‰ ë¬¸ì„œ", f"{docs_count}ê°œ")
        
    except Exception as e:
        st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
            st.text(traceback.format_exc())
        
        # ë¹ ë¥¸ í•´ê²°ì±… ì œì•ˆ
        st.info("ğŸ’¡ **ë¹ ë¥¸ í•´ê²°ì±…**: ì‚¬ì´ë“œë°”ì˜ 'ìºì‹œ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()
