# =============================================================================
# app.py - ë©”ì¸ Streamlit ì•±
# =============================================================================

import streamlit as st
import os
from langdetect import detect, DetectorFactory
from pathlib import Path
import sys
import traceback

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# ì–¸ì–´ ê°ì§€ ì‹œë“œ ê³ ì • (ì¼ê´€ì„±ì„ ìœ„í•´)
DetectorFactory.seed = 0

# ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
import config
from utils import (
    load_tokenizer,
    load_embeddings_and_index,
    build_prompt,
    generate_answer
)
from utils.embedding_index import search_similar_passages
from utils.generator import load_generation_models

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=config.PAGE_TITLE,
    page_icon=config.PAGE_ICON,
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
        border-bottom: 2px solid #e0e0e0;
        margin-bottom: 2rem;
    }
    .chat-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .legal-docs {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    .answer-box {
        background-color: #e8f5e8;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)

# ë©”ì¸ í—¤ë”
st.markdown(f"""
<div class="main-header">
    <h1>{config.PAGE_ICON} {config.PAGE_TITLE}</h1>
    <p>ì¤‘êµ­ì–´ì™€ ë² íŠ¸ë‚¨ì–´ë¥¼ ì§€ì›í•˜ëŠ” AI ë²•ë¥  ìƒë‹´ ì„œë¹„ìŠ¤</p>
</div>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("### ğŸ“‹ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. ì¤‘êµ­ì–´ ğŸ‡¨ğŸ‡³ ë˜ëŠ” ë² íŠ¸ë‚¨ì–´ ğŸ‡»ğŸ‡³ë¡œ ì§ˆë¬¸ ì…ë ¥
    2. ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ ìë™ ê²€ìƒ‰
    3. AIê°€ ë²•ë¥  ì¡°ë¬¸ì— ê¸°ë°˜í•œ ë‹µë³€ ì œê³µ
    """)
    
    st.markdown("### âš ï¸ ì£¼ì˜ì‚¬í•­")
    st.markdown("""
    - ë³¸ ì„œë¹„ìŠ¤ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤
    - ì¤‘ìš”í•œ ë²•ë¥  ë¬¸ì œëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”
    - ë‹µë³€ì˜ ì •í™•ì„±ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    """)
    
    st.markdown("### ğŸŒ ì§€ì› ì–¸ì–´")
    st.markdown("- ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ (Chinese)")
    st.markdown("- ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ì–´ (Vietnamese)")

# ë©”ì¸ ì½˜í…ì¸ 
def main():
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'initialized' not in st.session_state:
        with st.spinner("ğŸ”„ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                # ì–¸ì–´ë³„ ì„ë² ë”© ì‹œìŠ¤í…œ ë¡œë“œ
                (embed_model, cn_index, cn_passages, cn_metadata, 
                 vn_index, vn_passages, vn_metadata) = load_embeddings_and_index()
                
                if embed_model is None:
                    st.error("âŒ ì„ë² ë”© ì‹œìŠ¤í…œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
                
                # ìƒì„± ëª¨ë¸ ë¡œë“œ
                chinese_model, vietnamese_model = load_generation_models()
                
                if chinese_model is None or vietnamese_model is None:
                    st.error("âŒ ìƒì„± ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ì–¸ì–´ë³„ ë¶„ë¦¬)
                st.session_state.embed_model = embed_model
                st.session_state.cn_index = cn_index
                st.session_state.cn_passages = cn_passages
                st.session_state.cn_metadata = cn_metadata
                st.session_state.vn_index = vn_index
                st.session_state.vn_passages = vn_passages
                st.session_state.vn_metadata = vn_metadata
                st.session_state.chinese_model = chinese_model
                st.session_state.vietnamese_model = vietnamese_model
                st.session_state.initialized = True
                
                # ë¡œë“œëœ ë°ì´í„° í™•ì¸
                cn_count = len(cn_passages) if cn_passages else 0
                vn_count = len(vn_passages) if vn_passages else 0
                st.success(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ! (ğŸ‡¨ğŸ‡³ {cn_count}ê°œ, ğŸ‡»ğŸ‡³ {vn_count}ê°œ ë¬¸ì„œ)")
                
            except Exception as e:
                st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                st.stop()
    
    # ì§ˆë¬¸ ì…ë ¥
    st.markdown("### ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    question = st.text_input(
        "",
        placeholder="ì¤‘êµ­ì–´ ë˜ëŠ” ë² íŠ¸ë‚¨ì–´ë¡œ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
        key="question_input"
    )
    
    # ì˜ˆì‹œ ì§ˆë¬¸ë“¤
    st.markdown("#### ğŸ“ ì˜ˆì‹œ ì§ˆë¬¸")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¤ºä¾‹**")
        if st.button("æˆ‘å¯ä»¥åœ¨éŸ©å›½å·¥ä½œå¤šé•¿æ—¶é—´ï¼Ÿ", key="zh_example"):
            st.session_state.question_input = "æˆ‘å¯ä»¥åœ¨éŸ©å›½å·¥ä½œå¤šé•¿æ—¶é—´ï¼Ÿ"
            st.rerun()
    
    with col2:
        st.markdown("**ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t**")
        if st.button("TÃ´i cÃ³ thá»ƒ lÃ m viá»‡c á»Ÿ HÃ n Quá»‘c trong bao lÃ¢u?", key="vi_example"):
            st.session_state.question_input = "TÃ´i cÃ³ thá»ƒ lÃ m viá»‡c á»Ÿ HÃ n Quá»‘c trong bao lÃ¢u?"
            st.rerun()
    
    # ì§ˆë¬¸ ì²˜ë¦¬
    if question and question.strip():
        process_question(question.strip())

def process_question(question: str):
    """ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ìƒì„±"""
    try:
        # ì–¸ì–´ ê°ì§€
        detected_lang = detect(question)
        
        # ì§€ì›ë˜ëŠ” ì–¸ì–´ í™•ì¸
        if detected_lang not in ['zh', 'vi']:
            st.warning("âš ï¸ ì¤‘êµ­ì–´ ë˜ëŠ” ë² íŠ¸ë‚¨ì–´ë¡œë§Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
            return
        
        # ì–¸ì–´ í‘œì‹œ
        lang_display = {"zh": "ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´", "vi": "ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ì–´"}
        st.info(f"ê°ì§€ëœ ì–¸ì–´: {lang_display.get(detected_lang, detected_lang)}")
        
        # ì–¸ì–´ì— ë”°ë¥¸ ì¸ë±ìŠ¤ ë° íŒ¨ì‹œì§€ ì„ íƒ
        if detected_lang == "zh":
            faiss_index = st.session_state.cn_index
            passages = st.session_state.cn_passages
            metadata = st.session_state.cn_metadata
        else:  # detected_lang == "vi"
            faiss_index = st.session_state.vn_index  
            passages = st.session_state.vn_passages
            metadata = st.session_state.vn_metadata
        
        # í•´ë‹¹ ì–¸ì–´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if faiss_index is None or passages is None:
            lang_name = "ì¤‘êµ­ì–´" if detected_lang == "zh" else "ë² íŠ¸ë‚¨ì–´"
            st.error(f"âŒ {lang_name} ë²•ë¥  ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰
        with st.spinner("ğŸ” ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            retrieved_docs = search_similar_passages(
                st.session_state.embed_model,
                faiss_index,
                passages,
                question,
                k=config.MAX_RETRIEVED_DOCS
            )
        
        if not retrieved_docs:
            st.warning("ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²€ìƒ‰ëœ ë²•ë¥  ì¡°ë¬¸ í‘œì‹œ
        with st.expander("ğŸ” ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸", expanded=True):
            st.markdown('<div class="legal-docs">', unsafe_allow_html=True)
            for i, doc in enumerate(retrieved_docs, 1):
                score = doc.get('score', 0)
                st.markdown(f"**{i}. ë²•ì¡°ë¬¸** (ìœ ì‚¬ë„: {score:.3f})")
                st.markdown(f"{doc['text']}")
                st.markdown("---")
            st.markdown('</div>', unsafe_allow_html=True)
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        tokenizer = load_tokenizer(detected_lang)
        if tokenizer is None:
            st.error("í† í¬ë‚˜ì´ì € ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = build_prompt(question, retrieved_docs, detected_lang)
        
        # ëª¨ë¸ ì„ íƒ
        model = (st.session_state.chinese_model if detected_lang == "zh" 
                else st.session_state.vietnamese_model)
        
        # ë‹µë³€ ìƒì„±
        with st.spinner("ğŸ¤– ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            answer = generate_answer(prompt, model, tokenizer)
        
        # ë‹µë³€ í‘œì‹œ
        st.markdown("### ğŸ’¡ AI ë²•ë¥  ìƒë‹´ ë‹µë³€")
        st.markdown('<div class="answer-box">', unsafe_allow_html=True)
        st.markdown(answer)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ì¶”ê°€ ì•ˆë‚´
        st.markdown("---")
        st.markdown("**âš ï¸ ë©´ì±…ì¡°í•­:** ë³¸ ë‹µë³€ì€ AIê°€ ìƒì„±í•œ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤. ì •í™•í•œ ë²•ë¥  ìƒë‹´ì€ ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
    except Exception as e:
        st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
            st.text(traceback.format_exc())

if __name__ == "__main__":
    main()
